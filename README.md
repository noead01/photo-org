# Photo Organizer

Opinionated, local‑first photo library with **face detection**, **face search**, and **fast metadata queries** backed by **PostgreSQL + pgvector**. Designed for power users who want transparent data models, reproducible pipelines, and a web UI that asks for confirmation only when confidence is low.

---

## TL;DR

* **Stack:** Python (ingest + services), FastAPI, PostgreSQL 16+, `pgvector`, React/Next.js (UI).
* **Core:** EXIF/metadata indexing, face detection + 128‑D embeddings, vector search, active‑learning confirmations.
* **Scale target:** ~50k detected faces across ~200–250 known people; remaining faces remain “unknown” until confirmed.

---

## Features

* **Metadata ingest** (EXIF, file stats) with reproducible pipelines.
* **Face detection & crops** stored per photo with `(x,y,w,h)` and face bitmap.
* **Embeddings** (128‑D, compatible with `face_recognition`) stored in pgvector.
* **Similarity search** using `ivfflat`/`hnsw` indexes.
* **Active learning loop**: proposes IDs; requests confirmation only when needed; records provenance + confidence.
* **Priors**: optional heuristics from **timestamp**, **co‑occurrence clusters**, and **location** to boost/rank suggestions.
* **SQLite → Postgres migration** scripts.
* **REST API** for UI/automation.

---

## Architecture

```mermaid
flowchart LR
subgraph Filesystem
FS[Local Filesystem]
end


ING[Ingest Scripts
(EXIF, Faces)]
API[FastAPI Service
(Search/Confirm)]
DB[(PostgreSQL 16+
pgvector)]
UI[React/Next.js UI]
BATCH[Batch Jobs
(re-evaluate priors, indexes)]


FS --> ING --> API --> DB
UI <--> API
BATCH --> DB
```

**Key decisions**

* Use **128‑D embeddings** when generated by `face_recognition`; storing 512‑D is wasteful if the model outputs 128‑D.
* Create **IVFFlat/HNSW indexes only after you have enough rows**; otherwise Postgres warns about low recall (expected with tiny tables).
* All identification events are **timestamped** to support selective re‑evaluation of priors after confirmations.

---

## Data Model (excerpt)

### `photos`

* `photo_id UUID PK`
* `path TEXT` (absolute or repo‑root‑relative)
* `sha256 TEXT`, `phash TEXT`
* `filesize INT`, `ext TEXT`
* `created_ts TIMESTAMPTZ`, `modified_ts TIMESTAMPTZ`
* `shot_ts TIMESTAMPTZ`, `shot_ts_source TEXT`
* `faces_count INT`, `faces_detected_ts TIMESTAMPTZ` (optional)

### `faces`

* `face_id UUID PK`
* `photo_id UUID` → `photos(photo_id)`
* `bbox_x INT`, `bbox_y INT`, `bbox_w INT`, `bbox_h INT`
* `bitmap BYTEA` (optional crop)
* `embedding VECTOR(128)`  ⟵ if using `face_recognition`
* `provenance JSONB` (detector/model/version, thresholds)
* Index: `ivfflat (embedding) WITH (lists = 100)` (create once you have data)

### `people`

* `person_id UUID PK`
* `display_name TEXT`
* `created_ts TIMESTAMPTZ`

### `face_labels`

* `face_id UUID` → `faces`
* `person_id UUID` → `people`
* `label_source TEXT` ("human_confirmed" | "model_guess" | "imported")
* `confidence REAL`
* `created_ts TIMESTAMPTZ`

> Note: Columns and names may differ slightly from your local schema; align as needed. The system tolerates PK names that are **not** `id`.

---

## REST API (FastAPI)

*(Base path: `/api`)*

* **GET** `/photos?limit=&offset=&q=` — list/search photos.
* **GET** `/photos/{photo_id}` — one photo + faces.
* **GET** `/faces/{face_id}` — one face + metadata.
* **POST** `/faces/similar` — `{ face_id | embedding }` → similar faces.
* **POST** `/faces/{face_id}/label` — `{ person_id, confidence?, source }`.
* **GET** `/people` — list known people.
* **POST** `/people` — create person.
* **GET** `/search` — mixed search over photos/faces (text + vector).

> Error contracts are explicit; idempotency keys supported on mutating routes.

---

## Getting Started

### Prereqs

* Python **3.11+**
* PostgreSQL **16+** with `pgvector` extension
* (Optional) Docker + Docker Compose

### Quickstart (Docker Compose)

1. Copy `.env.example` → `.env` and set values.
2. `docker compose up -d` (starts Postgres + API + UI if included).
3. `alembic upgrade head` (or run the provided SQL schema).
4. Run an ingest to index a directory of photos:

   ```bash
   python -m tools.ingest \
     --root /path/to/photos \
     --exif --faces --thumbnails
   ```

### Local Dev (no Docker)

```bash
python -m venv .venv && source .venv/bin/activate
pip install -r requirements.txt
export DATABASE_URL=postgresql+psycopg://user:pass@localhost:5432/photoorg
# create extension in the *target* DB
psql "$DATABASE_URL" -c 'CREATE EXTENSION IF NOT EXISTS vector;'
# init schema
alembic upgrade head
```

### Environment

* `DATABASE_URL` — SQLAlchemy URL to Postgres
* `PGVECTOR_INDEX` — `ivfflat` or `hnsw` (default: `ivfflat`)
* `EMBEDDING_DIM` — (default: `128`)
* `INGEST_THUMBNAILS=1` — generate face crops
* `CONFIDENCE_CONFIRM_THRESHOLD` — ask user below this threshold

---

## Migration: SQLite → Postgres

* Order matters: copy **parent** tables before **children** to satisfy FKs.
* Identity/serial columns: **do not** insert explicit values unless needed; let Postgres assign.
* Primary key name **does not need** to be `id`; the script introspects PKs.
* Added progress prints at major steps (table copy start/end, row counts, index creation).
* If `vector` type is missing, ensure `CREATE EXTENSION vector;` **in the target DB**.

---

## Face Pipeline & Active Learning

1. **Detect** faces (e.g., `face_recognition`)
2. **Embed** into 128‑D vectors (store in `faces.embedding`)
3. **Search** similar via `pgvector`
4. **Rank** candidates with priors (shot time proximity, co‑occurrence, location)
5. **Propose** top‑k identities; **auto‑apply** above high threshold
6. **Confirm** below threshold via UI; write `face_labels` with provenance + ts
7. **Re‑evaluate**: batch job re‑scores neighbors since last `confirmation_ts`

> This keeps the system improving as you confirm more faces; relatives/co‑attendees surface naturally via co‑occurrence.

---

## UI Notes

* Web UI prompts for confirmation only when needed; “Unknown person” remains valid.
* Thumbnail panels show **face crops**; clicking opens full photo with bounding boxes.
* Accessibility: keyboard navigation, alt text, high‑contrast theme, and lazy loading.

---

## Vector Indexing Tips

* Build `ivfflat` with `lists = sqrt(N)` as a heuristic; tune empirically.
* Rebuild index after large data growth; analyze `ANALYZE` regularly.
* Expect the Postgres notice: *“ivfflat index created with little data”* when `N` is small — that’s normal; recall improves with more vectors.

---

## Scripts

* `tools/ingest` — scan folders, extract EXIF, detect faces, store crops
* `tools/migrate_sqlite_to_pg` — copy data in dependency order
* `tools/reindex_vectors` — (re)create ivfflat/hnsw
* `tools/recompute_priors` — periodic re‑ranking after new confirmations

---

## Testing

```bash
pytest -q
# optional: run only vector tests
pytest tests/test_vectors.py -q
```

---

## Roadmap

* [ ] People merge/split workflow (dedupe mistaken identities)
* [ ] On‑device face embedding (WebAssembly) for private uploads
* [ ] Map/timeline views (EXIF GPS + date buckets)
* [ ] Role‑based multi‑user support
* [ ] Export/Import bundle (photos + DB subset)
* [ ] Offline‑first PWA UI

---

## Troubleshooting

* **`type "vector" does not exist`** → run `CREATE EXTENSION vector;` in the **photoorg** DB.
* **Low recall warning on ivfflat** → add more data before relying on ANN; or use `hnsw`.
* **Different PK names** → scripts introspect; set `--pk-column` if needed.
* **Large batches** → increase `work_mem`, tune `maintenance_work_mem` during index builds.

---

## Contributing

PRs welcome. Keep changes atomic, include migration scripts, and add tests for:

* new columns/indexes
* API contracts
* vector‑search behavior (precision@k on fixtures)

---

## License

MIT (see `LICENSE`).

---

## Acknowledgments

* `pgvector` for vector search in Postgres
* `face_recognition` for simple 128‑D embeddings
* `exiftool` for robust metadata extraction
